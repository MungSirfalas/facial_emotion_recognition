{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMBlk/7rXMGjdLd5Wq9GMkI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.utils import to_categorical, img_to_array, image_dataset_from_directory\n","from keras.models import load_model\n","from keras.preprocessing import image\n","from keras import layers\n","from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"],"metadata":{"id":"gRh21RxkSayJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1. Load images and labels as Numpy array"],"metadata":{"id":"kv4mHgmECfrr"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OfOQoeswCZQS"},"outputs":[],"source":["def data_loader_np_array(path, map_labels, target_size, verbose=True):\n","    \"\"\"Function to load the images organized by label within a given path.\n","       Args:\n","           path: full directory to image folders by class.\n","           map_labels: dictionary to map labels to classes.\n","           target_size: final pixel size of images.\n","           verbose: if True, shows the count of loaded images per label.\n","       Returns:\n","           features: numpy array of transformed images.\n","           target_vector: numpy array of one-hot encoded labels.\n","    \"\"\"\n","\n","    # feature and label lists\n","    data = []\n","    labels = []\n","\n","    # read images from directory\n","    for label, emotion in map_labels.items():\n","        files = os.listdir(os.path.join(path, emotion).replace(\"\\\\\", \"/\"))\n","        images = [file for file in files if file.endswith(\"jpg\")]\n","        if verbose:\n","            print(\"Reading {} images found for {}\".format(len(images), emotion))\n","        for image_name in images:\n","            image = cv2.imread(os.path.join(path, emotion, image_name).replace(\"\\\\\", \"/\"))\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","            image = cv2.resize(image, (target_size, target_size))\n","            image = image.reshape(target_size, target_size, 1)/255.0\n","            data.append(image)\n","            labels.append(label)\n","\n","    # to numpy arrays and apply one-hot enconding\n","    data, labels = np.array(data), to_categorical(np.array(labels))\n","\n","    # shuffle dataset\n","    perm = np.random.permutation(len(data))\n","    features, target_vector = np.array(data)[perm], labels[perm]\n","\n","    return features, target_vector"]},{"cell_type":"markdown","source":["### 2. Load images and labels as TensorFlow dataset"],"metadata":{"id":"fmQ8RLO0Cr6t"}},{"cell_type":"code","source":["def data_loader_tf_dataset(path, batch_size, target_size, augmentation=False, shuffle=True, transfer_learning=False):\n","    \"\"\"Function to 1) apply data augmentation; 2) trasform images to grayscale and scale to (0, 1);\n","       and 3) to apply one hot encoding to labels.\n","        Args:\n","            path: full directory to read images from.\n","            batch_size: the number of images per batch.\n","            target_size: final pixel size of images.\n","            augmentation: if True, data augmentation is applied.\n","            shuffle: if True, the dataset elements are shuffled.\n","        Returns:\n","            dataset: a A tf.data.Dataset object.  it yields a tuple (images, labels),\n","            where images has shape (batch_size, image_size[0], image_size[1], 1),\n","            and labels are a float32 tensor of shape (batch_size, num_classes),\n","            representing a one-hot encoding of the class index.\n","    \"\"\"\n","    # data transformer\n","    if augmentation:\n","        data_augmentation = keras.models.Sequential()\n","        data_augmentation.add(layers.Resizing(target_size, target_size))\n","        data_augmentation.add(layers.Rescaling(scale=1.0/255))\n","        data_augmentation.add(layers.RandomRotation(factor=0.17)) # 10 degrees = 0.17(2*pi)\n","        data_augmentation.add(layers.RandomFlip(\"horizontal\"))\n","        data_augmentation.add(layers.RandomZoom(height_factor=0.1, width_factor=0.1))\n","    else:\n","        data_augmentation = keras.models.Sequential()\n","        data_augmentation.add(layers.Resizing(target_size, target_size))\n","        data_augmentation.add(layers.Rescaling(scale=1.0/255))\n","\n","    # image filters for transfer learning\n","    if transfer_learning:\n","        color_mode = \"rgb\"\n","    else:\n","        color_mode = \"grayscale\"\n","\n","    # load data from directory and transform\n","    dataset = image_dataset_from_directory(path,\n","                                           labels=\"inferred\",\n","                                           label_mode=\"categorical\",\n","                                           image_size=(target_size, target_size),\n","                                           color_mode=color_mode,\n","                                           batch_size=batch_size,\n","                                           shuffle=shuffle)\n","\n","    # cache dataset for gpu computing\n","    dataset = dataset.map(lambda x, y: (data_augmentation(x), y),\n","                          num_parallel_calls=tf.data.AUTOTUNE)\\\n","                     .cache()\\\n","                     .prefetch(tf.data.AUTOTUNE)\n","\n","    return dataset"],"metadata":{"id":"ccWhOBS_C2v7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3. Load single model to predict"],"metadata":{"id":"AF7BTCHIM6BQ"}},{"cell_type":"code","source":["def load_predict(model, dataset):\n","    \"\"\"Function to to load a model and make predictions.\n","        Args:\n","            path: full directory to model.\n","            model: name of the model to be loaded.\n","            dataset: a A tf.data.Dataset object.  it yields a tuple (images, labels),\n","            where images has shape (batch_size, image_size[0], image_size[1], 1),\n","            and labels are a float32 tensor of shape (batch_size, num_classes),\n","            representing a one-hot encoding of the class index.\n","        Returns:\n","            y_true: true labels.\n","            y_pred: predicted labels.\n","    \"\"\"\n","\n","    # get true labels on data set\n","    y_true = np.asarray(list(dataset.unbatch().map(lambda x, y: y)))\n","\n","    # get true labels from one-hot encoded results\n","    y_true = [np.argmax(i) for i in y_true]\n","\n","    # predictions on dataset\n","    y_pred = model.predict(dataset)\n","\n","    # get most probable predicted label\n","    y_pred = [np.argmax(i) for i in y_pred]\n","\n","    return y_true, y_pred"],"metadata":{"id":"IkvQxxxiM6S9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4. Load and ensemble models to predict"],"metadata":{"id":"ROYy3y1tQACJ"}},{"cell_type":"code","source":["def load_ensemble_predict(path, model_list, dataset):\n","    \"\"\"Function to to load a model and make predictions.\n","        Args:\n","            path: full directory to folders containing each model.\n","            model: name of the model to be loaded.\n","            dataset: a A tf.data.Dataset object.  it yields a tuple (images, labels),\n","            where images has shape (batch_size, image_size[0], image_size[1], 1),\n","            and labels are a float32 tensor of shape (batch_size, num_classes),\n","            representing a one-hot encoding of the class index.\n","        Returns:\n","            y_true: true labels.\n","            y_pred: predicted labels.\n","    \"\"\"\n","\n","    # load model\n","    model = load_model(\"{}/{}/{}.h5\".format(path, model, model))\n","\n","    # get true labels on data set\n","    y_true = np.asarray(list(dataset.unbatch().map(lambda x, y: y)))\n","\n","    # get true labels from one-hot encoded results\n","    y_true = [np.argmax(i) for i in y_true]\n","\n","    # predictions on dataset\n","    y_pred = model.predict(dataset)\n","\n","    # get most probable predicted label\n","    y_pred = [np.argmax(i) for i in y_pred]\n","\n","    return y_true, y_pred"],"metadata":{"id":"aj3lM94VP9f-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4. Plot learning curves"],"metadata":{"id":"hWyyRZmcDKHX"}},{"cell_type":"code","source":["def learning_curve(history, epochs):\n","    \"\"\"Function to plot learning curves\n","        Args:\n","            history: history of CNN model trained with Keras\n","        Returns:\n","            plot of the learning curves for the classifier\n","    \"\"\"\n","    fig = plt.figure(figsize=(7, 5))\n","    ax = plt.axes()\n","    pd.DataFrame(history.history).plot(ax=ax)\n","    ax.grid(True)\n","    ax.set_xlim(0, epochs)\n","    ax.set_ylim(0, 2)\n","    plt.show()"],"metadata":{"id":"E1ZfpFW1DKoL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def learning_curve_from_file(path, model_name):\n","    \"\"\"Function to plot learning curves\n","        Args:\n","            path: path to files\n","            model_name: name of the model\n","        Returns:\n","            plot of the learning curves for the classifier\n","    \"\"\"\n","    # load data\n","    df = pd.read_csv(\"{}/{}/{}_lc.csv\".format(path, model_name, model_name))\n","    df[\"epoch\"] = df.index\n","\n","    # plot data\n","    n_epochs = df[\"epoch\"].max() + 1\n","    fig, ax = plt.subplots(figsize=(5, 3))\n","    df.plot(x=\"epoch\", y=[\"loss\", \"val_loss\"], ax=ax,\n","            xlim=(0, n_epochs), ylim=(0.5, 2),\n","            xlabel=\"epoca\", ylabel=\"pérdida\",\n","            grid=True, color=[\"blue\", \"red\"])\n","    ax.legend([\"train\", \"validation\"], frameon=False)\n","    plt.rcParams['figure.dpi'] = 100"],"metadata":{"id":"9JVlfbPpGDmY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5. Confusion matrix"],"metadata":{"id":"-40Hs2oGzL6v"}},{"cell_type":"code","source":["def confusion_matrix_report(model, dataset, label_dictionary):\n","    # load model and make predictions\n","    true_labels, predicted_labels = load_predict(model, dataset)\n","\n","    # confusion matrix\n","    matrix = confusion_matrix([label_dictionary[i] for i in true_labels], [label_dictionary[i] for i in predicted_labels])\n","\n","    # classification report\n","    class_report = classification_report([label_dictionary[i] for i in true_labels], [label_dictionary[i] for i in predicted_labels])\n","\n","    # print confusion matrix and classification report\n","    print('Matrix de confusión')\n","    print()\n","    fig = plt.figure(figsize=(4, 3))\n","    sns.heatmap(matrix, annot=True, fmt=\"d\", annot_kws={\"size\": 8},\n","                xticklabels=[label_dictionary[i] for i in range(len(label_dictionary))],\n","                yticklabels=[label_dictionary[i] for i in range(len(label_dictionary))])\n","    plt.xlabel(\"Clases predichas\")\n","    plt.xticks(rotation=45, ha='right')\n","    plt.ylabel(\"Clases reales\")\n","    plt.show()\n","    print()\n","    print()\n","    print('Reporte clasificacion:')\n","    print()\n","    print(class_report)"],"metadata":{"id":"wGn14fMEzJzq"},"execution_count":null,"outputs":[]}]}